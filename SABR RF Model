# -*- coding: utf-8 -*-
"""PyBaseball.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1BZ3IYkf_Kka410P_Hne0RCZRT84UWPFm
"""

!pip install pybaseball

from pybaseball import statcast
data = statcast(start_dt='2017-06-24', end_dt='2017-06-27')
data.head(2)

from pybaseball import pitching_stats
data = pitching_stats(2012, 2016)
data.head()

from pybaseball import playerid_lookup
from pybaseball import statcast_pitcher
import pandas as pd
csv = '2019pitchers.csv'
df = pd.read_csv(csv)
print(df)

import pandas as pd
alldata = statcast_pitcher('2019-03-27', '2019-11-01', df.get_value(0, 'MLBID'))
for i in range(1, 121): 
  data = statcast_pitcher('2019-03-27', '2019-11-01', df.get_value(i, 'MLBID'))
  data = data[::-1]
  alldata = pd.concat([alldata, data])
print(alldata)

import pandas as pd
kershaw = pd.DataFrame(alldata)
print(kershaw)

a = 18
df1 = kershaw[kershaw['at_bat_number'] <= a]
df1_ = kershaw[kershaw['at_bat_number'] > a]
print(df1)
print(df1_)

df1 = df1.fillna(0)
df1 = df1[df1.pitch_type != 0]
df2 = df1.pitch_type.str.contains("SI")
print(df2)

# Commented out IPython magic to ensure Python compatibility.
# %%capture
# !pip install eli5
# 
# from sklearn.linear_model import LogisticRegression
# from sklearn.ensemble import RandomForestRegressor
# import numpy as np
# import pandas as pd
# import eli5
# from sklearn.model_selection import train_test_split
# from sklearn.model_selection import cross_val_score
# from eli5.sklearn import PermutationImportance
# import statistics
# from sklearn.model_selection import GridSearchCV
# from sklearn.metrics import mean_absolute_error
# from sklearn.metrics import classification_report
# import sklearn.metrics as metrics
# from sklearn.model_selection import RandomizedSearchCV
# import sklearn.model_selection
# from sklearn.svm import SVR

label = 'woba_value'
df2 = df1.select_dtypes(exclude=['object'])
df3 = df2.fillna(0)
df3=(df3-df3.mean())/df3.std()
df3 = df3.fillna(0)
#df4 = df3.drop(['woba_denom'], axis=1).drop(['woba_value'], axis=1).drop(['iso_value'], axis=1).drop(['hc_y'], axis=1).drop(['babip_value'], axis=1).drop(['hit_location'], axis=1).drop(['hc_x'], axis=1).drop(['estimated_ba_using_speedangle'], axis=1).drop(['estimated_woba_using_speedangle'], axis=1).drop(['launch_speed'], axis=1).drop(['hit_distance_sc'], axis=1).drop(['on_1b'], axis=1).drop(['on_2b'], axis=1).drop(['on_3b'], axis=1).drop(['umpire'], axis=1).drop(['launch_speed_angle'], axis=1).drop(['break_length_deprecated'], axis=1).drop(['break_angle_deprecated'], axis=1).drop(['spin_rate_deprecated'], axis=1).drop(['tfs_deprecated'], axis=1).drop(['tfs_zulu_deprecated'], axis=1)
df4 = df3.drop(['woba_denom'], axis=1).drop(['hit_location'], axis=1).drop(['launch_speed_angle'], axis=1).drop(['launch_angle'], axis=1).drop(['iso_value'], axis=1).drop(['babip_value'], axis=1).drop(['hc_x'], axis=1).drop(['estimated_ba_using_speedangle'], axis=1).drop(['estimated_woba_using_speedangle'], axis=1).drop(['on_1b'], axis=1).drop(['on_2b'], axis=1).drop(['on_3b'], axis=1).drop(['umpire'], axis=1).drop(['break_length_deprecated'], axis=1).drop(['break_angle_deprecated'], axis=1).drop(['spin_rate_deprecated'], axis=1).drop(['tfs_deprecated'], axis=1).drop(['tfs_zulu_deprecated'], axis=1)
X = df4.drop([label], axis=1)
y = df4[label]
trainX, testX, trainY, testY = train_test_split(X, y, test_size=0.5, random_state=1)

pd.options.display.max_rows = 4000

def run(model, model_name='this model', trainX=trainX, trainY=trainY, testX=testX, testY=testY):
    model.fit(trainX, trainY)
    accuracies = []
    for i in range(10):
      accuracies.append(model.score(trainX,trainY))
    accuracy = statistics.mean(accuracies)
    testAccuracy = model.score(testX, testY)
    print("Training accuracy of "+model_name+" is: ", accuracy*100)
    print("Testing accuracy of "+model_name+" is: ", testAccuracy*100)
    print('\n')

rf = RandomForestRegressor(n_estimators=100)
run(rf, 'Random Forest')

feature_names = list(trainX.columns)
model = rf
perm = PermutationImportance(model, random_state=1).fit(testX, testY)
eli5.show_weights(perm, feature_names=feature_names, top=100)

def results(y_true, y_pred):

    # Regression metrics
    explained_variance=metrics.explained_variance_score(y_true, y_pred)
    mean_absolute_error=metrics.mean_absolute_error(y_true, y_pred) 
    mse=metrics.mean_squared_error(y_true, y_pred) 
    #mean_squared_log_error=metrics.mean_squared_log_error(y_true, y_pred)
    median_absolute_error=metrics.median_absolute_error(y_true, y_pred)
    r2=metrics.r2_score(y_true, y_pred)

    print('explained_variance: ', round(explained_variance,4))    
    #print('mean_squared_log_error: ', round(mean_squared_log_error,4))
    print('r2: ', round(r2,4))
    print('MAE: ', round(mean_absolute_error,4))
    print('MSE: ', round(mse,4))
    print('RMSE: ', round(np.sqrt(mse),4))

results(testY,model.predict(testX))

label = 'woba_value'
df2_ = df1_.select_dtypes(exclude=['object'])
df3_ = df2_.fillna(0)
#df4 = df3.drop(['woba_denom'], axis=1).drop(['woba_value'], axis=1).drop(['iso_value'], axis=1).drop(['hc_y'], axis=1).drop(['babip_value'], axis=1).drop(['hit_location'], axis=1).drop(['hc_x'], axis=1).drop(['estimated_ba_using_speedangle'], axis=1).drop(['estimated_woba_using_speedangle'], axis=1).drop(['launch_speed'], axis=1).drop(['hit_distance_sc'], axis=1).drop(['on_1b'], axis=1).drop(['on_2b'], axis=1).drop(['on_3b'], axis=1).drop(['umpire'], axis=1).drop(['launch_speed_angle'], axis=1).drop(['break_length_deprecated'], axis=1).drop(['break_angle_deprecated'], axis=1).drop(['spin_rate_deprecated'], axis=1).drop(['tfs_deprecated'], axis=1).drop(['tfs_zulu_deprecated'], axis=1)
df4_ = df3_.drop(['woba_denom'], axis=1).drop(['hit_location'], axis=1).drop(['launch_speed_angle'], axis=1).drop(['launch_angle'], axis=1).drop(['iso_value'], axis=1).drop(['babip_value'], axis=1).drop(['hc_x'], axis=1).drop(['estimated_ba_using_speedangle'], axis=1).drop(['estimated_woba_using_speedangle'], axis=1).drop(['on_1b'], axis=1).drop(['on_2b'], axis=1).drop(['on_3b'], axis=1).drop(['umpire'], axis=1).drop(['break_length_deprecated'], axis=1).drop(['break_angle_deprecated'], axis=1).drop(['spin_rate_deprecated'], axis=1).drop(['tfs_deprecated'], axis=1).drop(['tfs_zulu_deprecated'], axis=1)
X = df4_.drop([label], axis=1)
y = df4_[label]
trainX, testX, trainY, testY = train_test_split(X, y, test_size=0.5, random_state=1)

def run(model, model_name='this model', trainX=trainX, trainY=trainY, testX=testX, testY=testY):
    model.fit(trainX, trainY)
    accuracies = []
    for i in range(10):
      accuracies.append(model.score(trainX,trainY))
    accuracy = statistics.mean(accuracies)
    testAccuracy = model.score(testX, testY)
    print("Training accuracy of "+model_name+" is: ", accuracy*100)
    print("Testing accuracy of "+model_name+" is: ", testAccuracy*100)
    print('\n')

rf = RandomForestRegressor(n_estimators=100)
run(rf, 'Random Forest')

feature_names = list(trainX.columns)
model = rf
perm = PermutationImportance(model, random_state=1).fit(testX, testY)
eli5.show_weights(perm, feature_names=feature_names, top=100)

results(testY,model.predict(testX))
